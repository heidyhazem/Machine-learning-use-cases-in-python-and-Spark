{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Recommendation engines using pyspark "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations Are Everywhere!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "20 million ratings and 465,000 tag applications applied to 27,000 movies by 138,000 users. Includes tag genome data with 12 million relevance scores across 1,100 tags. Released 4/2015; updated 10/2016 to update links.csv and add tag genome data.\n",
    "\n",
    "source : https://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('RS') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = spark.read\\\n",
    "            .format('csv')\\\n",
    "            .option('header', 'true')\\\n",
    "            .load('ml-20m/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userId', 'movieId', 'rating', 'timestamp']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|      2|   3.5|1112486027|\n",
      "|     1|     29|   3.5|1112484676|\n",
      "|     1|     32|   3.5|1112484819|\n",
      "|     1|     47|   3.5|1112484727|\n",
      "|     1|     50|   3.5|1112484580|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate sparsity\n",
    "As you know, ALS works well with sparse datasets. Let's see how much of the ratings matrix is actually empty.\n",
    "<img src=\"sparsity.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratings dataframe is  99.46% empty.\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of ratings in the dataset\n",
    "numerator = ratings.select(\"rating\").count()\n",
    "\n",
    "# Count the number of distinct userIds and distinct movieIds\n",
    "num_users = ratings.select(\"userId\").distinct().count()\n",
    "num_movies = ratings.select(\"movieId\").distinct().count()\n",
    "\n",
    "# Set the denominator equal to the number of users multiplied by the number of movies\n",
    "denominator = num_users * num_movies\n",
    "\n",
    "# Divide the numerator by the denominator\n",
    "#The 1.0 is added to ensure the sparsity is returned as a decimal and not an integer.\n",
    "\n",
    "sparsity = (1.0 - (numerator *1.0)/denominator)*100\n",
    "print(\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|   296|   25|\n",
      "|   467|   30|\n",
      "|   675|  187|\n",
      "|   691|   35|\n",
      "|   829|  387|\n",
      "|  1090|   74|\n",
      "|  1159|  235|\n",
      "|  1436|  234|\n",
      "|  1512|   68|\n",
      "|  1572|   64|\n",
      "|  2069|   45|\n",
      "|  2088|   87|\n",
      "|  2136|  201|\n",
      "|  2162|  100|\n",
      "|  2294|   21|\n",
      "|  2904|   23|\n",
      "|  3210|  452|\n",
      "|  3414|   29|\n",
      "|  3606|   66|\n",
      "|  3959|   24|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group data by userId, count ratings\n",
    "ratings.groupBy(\"userId\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MovieLens Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie with the fewest ratings: \n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|         1|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Min num ratings for movies\n",
    "print(\"Movie with the fewest ratings: \")\n",
    "ratings.groupBy(\"movieId\").count().agg({\"count\": \"min\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg num ratings per movie: \n",
      "+-------+------------------+\n",
      "|movieId|       avg(rating)|\n",
      "+-------+------------------+\n",
      "|    296| 4.174231169217055|\n",
      "|   1090| 3.919977226720648|\n",
      "|   3959| 3.699372603694667|\n",
      "|   2294| 3.303207714257601|\n",
      "|   6731|3.5571184995737424|\n",
      "|  48738| 3.895868364160461|\n",
      "|   3210|3.6711219879518073|\n",
      "|  88140|3.5536100302637266|\n",
      "|    467|3.3832658569500675|\n",
      "|   2088| 2.562729584628426|\n",
      "|   2069| 3.806294326241135|\n",
      "|  50802|  2.85519801980198|\n",
      "|    829|2.6765513454146075|\n",
      "|   2136| 2.849462365591398|\n",
      "|  89864|3.8558174523570714|\n",
      "|   2904|3.5884353741496597|\n",
      "|   4821|3.1852010265183917|\n",
      "|  62912|2.3253676470588234|\n",
      "|  55498|2.9166666666666665|\n",
      "|   2162|2.4223394055608822|\n",
      "+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Avg num ratings per movie\n",
    "print(\"Avg num ratings per movie: \")\n",
    "ratings.groupBy(\"movieId\").agg({\"rating\": \"avg\"}).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User with the fewest ratings: \n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|        20|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Min num ratings for user\n",
    "print(\"User with the fewest ratings: \")\n",
    "ratings.groupBy(\"userId\").count().agg({\"count\": \"min\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Schema\n",
    "Spark's implementation of ALS requires that movieIds and userIds be provided as numeric datatypes. Many datasets need to be prepared accordingly in order for them to function properly with Spark. A common issue is that Spark thinks numbers are strings, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We have a problem in the schema\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#let's fix it\n",
    "# Tell Spark to convert the columns to the proper data types\n",
    "ratings = ratings.select(ratings.userId.cast(\"integer\"), ratings.movieId.cast(\"integer\"), \\\n",
    "                         ratings.rating.cast(\"double\"))\n",
    "\n",
    "# Call .printSchema() again to confirm the columns are now in the correct format\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "| 20132|    148|   3.0| 2.6610093|\n",
      "| 22884|    148|   3.0| 2.4764576|\n",
      "| 96427|    148|   3.0|   3.07394|\n",
      "|  1259|    148|   5.0|  3.346315|\n",
      "| 60081|    148|   2.0| 2.8290722|\n",
      "|130122|    148|   3.0|  2.803703|\n",
      "| 36445|    148|   4.5| 2.3015115|\n",
      "| 46146|    148|   2.0| 1.8508147|\n",
      "| 46944|    148|   2.0| 2.8999782|\n",
      "| 60334|    148|   4.0| 2.9264936|\n",
      "| 64843|    148|   3.5|  2.607587|\n",
      "|101628|    148|   1.0| 2.9659145|\n",
      "|111523|    148|   2.0|  3.249845|\n",
      "| 23115|    148|   1.0|  2.847929|\n",
      "| 61815|    148|   3.0| 3.5685768|\n",
      "|109910|    148|   2.0| 2.2265484|\n",
      "|  9084|    148|   2.0| 2.8719149|\n",
      "| 86098|    148|   3.0| 2.7471077|\n",
      "| 65304|    148|   2.0| 2.9384236|\n",
      "| 17655|    148|   4.0| 3.1932292|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "(training_data, test_data) = ratings.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", rank =10, maxIter =15, regParam =0.1,\n",
    "          coldStartStrategy=\"drop\", nonnegative =True, implicitPrefs = False)\n",
    "\n",
    "# Fit the mdoel to the training_data\n",
    "model = als.fit(training_data)\n",
    "\n",
    "# Generate predictions on the test_data\n",
    "test_predictions = model.transform(test_data)\n",
    "test_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build RMSE evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse\n",
      "rating\n",
      "prediction\n"
     ]
    }
   ],
   "source": [
    "# Complete the evaluator code\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Extract the 3 parameters\n",
    "print(evaluator.getMetricName())\n",
    "print(evaluator.getLabelCol())\n",
    "print(evaluator.getPredictionCol())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "| 20132|    148|   3.0| 2.6610093|\n",
      "| 22884|    148|   3.0| 2.4764576|\n",
      "| 96427|    148|   3.0|   3.07394|\n",
      "|  1259|    148|   5.0|  3.346315|\n",
      "| 60081|    148|   2.0| 2.8290722|\n",
      "|130122|    148|   3.0|  2.803703|\n",
      "| 36445|    148|   4.5| 2.3015115|\n",
      "| 46146|    148|   2.0| 1.8508147|\n",
      "| 46944|    148|   2.0| 2.8999782|\n",
      "| 60334|    148|   4.0| 2.9264936|\n",
      "| 64843|    148|   3.5|  2.607587|\n",
      "|101628|    148|   1.0| 2.9659145|\n",
      "|111523|    148|   2.0|  3.249845|\n",
      "| 23115|    148|   1.0|  2.847929|\n",
      "| 61815|    148|   3.0| 3.5685768|\n",
      "|109910|    148|   2.0| 2.2265484|\n",
      "|  9084|    148|   2.0| 2.8719149|\n",
      "| 86098|    148|   3.0| 2.7471077|\n",
      "| 65304|    148|   2.0| 2.9384236|\n",
      "| 17655|    148|   4.0| 3.1932292|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8117289044037578\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the \"test_predictions\" dataframe\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "\n",
    "# Print the RMSE\n",
    "print (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An RMSE of 0.811 means that on average the model predicts 0.811 above or below values of the original ratings matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Recommendations\n",
    "\n",
    "recommendForAllUsers(N) : is native spark function that gets top N recommendations for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_recommendations = model.recommendForAllUsers(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the output is not very human readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   148|[[126219, 5.89320...|\n",
      "|   463|[[126219, 6.24572...|\n",
      "|   471|[[126219, 5.58470...|\n",
      "|   496|[[121029, 6.21010...|\n",
      "|   833|[[126219, 6.10001...|\n",
      "|  1088|[[77736, 5.424657...|\n",
      "|  1238|[[126219, 6.04946...|\n",
      "|  1342|[[128830, 6.24111...|\n",
      "|  1580|[[93008, 4.587152...|\n",
      "|  1591|[[126219, 7.16933...|\n",
      "|  1645|[[121029, 5.64239...|\n",
      "|  1829|[[121029, 6.50329...|\n",
      "|  1959|[[121029, 5.33813...|\n",
      "|  2122|[[128830, 4.78646...|\n",
      "|  2142|[[126219, 6.49672...|\n",
      "|  2366|[[126219, 6.54641...|\n",
      "|  2659|[[121029, 5.81776...|\n",
      "|  2866|[[126219, 5.59148...|\n",
      "|  3175|[[126219, 8.15337...|\n",
      "|  3749|[[126219, 6.24814...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "als_recommendations.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning up recommendation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_recommendations.registerTempTable(\"ALS_recs_temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now it is readable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_recs = spark.sql(\"SELECT userId,\\\n",
    "                       movieIds_and_ratings.movieId AS movieId,\\\n",
    "                       movieIds_and_ratings.rating AS prediction\\\n",
    "                       FROM ALS_recs_temp\\\n",
    "                       LATERAL VIEW explode(recommendations) exploded_table\\\n",
    "                       AS movieIds_and_ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "|userId|movieId|prediction|\n",
      "+------+-------+----------+\n",
      "|   148| 126219| 5.8932056|\n",
      "|   148| 120821| 5.8524375|\n",
      "|   148| 121029|  5.594061|\n",
      "|   148|  77736|  5.418714|\n",
      "|   148|  86237| 5.4100146|\n",
      "|   463| 126219|  6.245726|\n",
      "|   463| 117907| 5.7048626|\n",
      "|   463| 121029| 5.6821766|\n",
      "|   463|  77736|  5.529721|\n",
      "|   463| 128830| 5.5152845|\n",
      "+------+-------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_recs.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And now we will join it with the movie info to be more readable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_info = spark.read\\\n",
    "            .format('csv')\\\n",
    "            .option('header', 'true')\\\n",
    "            .load('ml-20m/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_info.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now we can see what's going on even better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+--------------------+------------------+\n",
      "|movieId|userId|prediction|               title|            genres|\n",
      "+-------+------+----------+--------------------+------------------+\n",
      "| 126219|   148| 5.8932056|    Marihuana (1936)| Documentary|Drama|\n",
      "| 120821|   148| 5.8524375|The War at Home (...|   Documentary|War|\n",
      "| 121029|   148|  5.594061|No Distance Left ...|       Documentary|\n",
      "|  77736|   148|  5.418714|Crazy Stone (Feng...|      Comedy|Crime|\n",
      "|  86237|   148| 5.4100146|  Connections (1978)|       Documentary|\n",
      "| 126219|   463|  6.245726|    Marihuana (1936)| Documentary|Drama|\n",
      "| 117907|   463| 5.7048626|My Brother Tom (2...|             Drama|\n",
      "| 121029|   463| 5.6821766|No Distance Left ...|       Documentary|\n",
      "|  77736|   463|  5.529721|Crazy Stone (Feng...|      Comedy|Crime|\n",
      "| 128830|   463| 5.5152845|  Plastic Bag (2009)|             Drama|\n",
      "| 126219|   471| 5.5847054|    Marihuana (1936)| Documentary|Drama|\n",
      "|  77736|   471| 5.4270425|Crazy Stone (Feng...|      Comedy|Crime|\n",
      "| 121029|   471| 5.4005613|No Distance Left ...|       Documentary|\n",
      "|  85205|   471| 5.1918893|Merry Widow, The ...|     Drama|Romance|\n",
      "| 120821|   471|  5.146813|The War at Home (...|   Documentary|War|\n",
      "| 121029|   496|  6.210109|No Distance Left ...|       Documentary|\n",
      "| 126219|   496|  6.155118|    Marihuana (1936)| Documentary|Drama|\n",
      "| 117907|   496|  6.112196|My Brother Tom (2...|             Drama|\n",
      "| 129536|   496| 5.8166833|Code Name Coq Rou...|(no genres listed)|\n",
      "|  77736|   496|  5.769195|Crazy Stone (Feng...|      Comedy|Crime|\n",
      "+-------+------+----------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_recs.join(movie_info, [\"movieId\"],\"left\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And if we added filter after joinning with rating we can see nulls as the model predicts ratings for the movies that the individual user has not seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+------+\n",
      "|userId|movieId|prediction|rating|\n",
      "+------+-------+----------+------+\n",
      "|     9| 126219| 5.8424616|  null|\n",
      "|    17| 126219|  7.378057|  null|\n",
      "|    19| 121029|  6.148024|  null|\n",
      "|   192| 121029|  6.768174|  null|\n",
      "|   353| 117907|  5.402604|  null|\n",
      "|   370| 129536| 5.2093616|  null|\n",
      "|   377|  77736|   5.47226|  null|\n",
      "|   416|  77736| 5.5944695|  null|\n",
      "|   452| 126219| 6.9562807|  null|\n",
      "|   464|  77736| 4.2560515|  null|\n",
      "|   477| 126219| 5.8053718|  null|\n",
      "|   535| 121029| 5.9514947|  null|\n",
      "|   628| 129536| 5.6074753|  null|\n",
      "|   667| 107890|   5.14787|  null|\n",
      "|   670| 121029|  6.206175|  null|\n",
      "|   686| 126219|  5.537974|  null|\n",
      "|   715|  77736|  5.404034|  null|\n",
      "|   721| 117907|  5.650877|  null|\n",
      "|   731| 121029|  5.678696|  null|\n",
      "|   739|  77736|  5.632146|  null|\n",
      "+------+-------+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_recs.join(ratings, [\"userId\",\"movieId\"],\"left\")\\\n",
    ".filter(ratings.rating.isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Recommendations Make Sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+--------------------+--------------------+\n",
      "|movieId|userId|rating|               title|              genres|\n",
      "+-------+------+------+--------------------+--------------------+\n",
      "|      2|     1|   3.5|      Jumanji (1995)|Adventure|Childre...|\n",
      "|     29|     1|   3.5|City of Lost Chil...|Adventure|Drama|F...|\n",
      "|     32|     1|   3.5|Twelve Monkeys (a...|Mystery|Sci-Fi|Th...|\n",
      "|     47|     1|   3.5|Seven (a.k.a. Se7...|    Mystery|Thriller|\n",
      "|     50|     1|   3.5|Usual Suspects, T...|Crime|Mystery|Thr...|\n",
      "|    112|     1|   3.5|Rumble in the Bro...|Action|Adventure|...|\n",
      "|    151|     1|   4.0|      Rob Roy (1995)|Action|Drama|Roma...|\n",
      "|    223|     1|   4.0|       Clerks (1994)|              Comedy|\n",
      "|    253|     1|   4.0|Interview with th...|        Drama|Horror|\n",
      "|    260|     1|   4.0|Star Wars: Episod...|Action|Adventure|...|\n",
      "|    293|     1|   4.0|Léon: The Profess...|Action|Crime|Dram...|\n",
      "|    296|     1|   4.0| Pulp Fiction (1994)|Comedy|Crime|Dram...|\n",
      "|    318|     1|   4.0|Shawshank Redempt...|         Crime|Drama|\n",
      "|    337|     1|   3.5|What's Eating Gil...|               Drama|\n",
      "|    367|     1|   3.5|    Mask, The (1994)|Action|Comedy|Cri...|\n",
      "|    541|     1|   4.0| Blade Runner (1982)|Action|Sci-Fi|Thr...|\n",
      "|    589|     1|   3.5|Terminator 2: Jud...|       Action|Sci-Fi|\n",
      "|    593|     1|   3.5|Silence of the La...|Crime|Horror|Thri...|\n",
      "|    653|     1|   3.0|  Dragonheart (1996)|Action|Adventure|...|\n",
      "|    919|     1|   3.5|Wizard of Oz, The...|Adventure|Childre...|\n",
      "+-------+------+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original_ratings = ratings.join(movie_info, [\"movieId\"],\"left\")\n",
    "original_ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice the genre!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 60's Ratings:\n",
      "+-------+------+------+--------------------+--------------------+\n",
      "|movieId|userId|rating|               title|              genres|\n",
      "+-------+------+------+--------------------+--------------------+\n",
      "|   5816|    60|   5.0|Harry Potter and ...|   Adventure|Fantasy|\n",
      "|   1197|    60|   5.0|Princess Bride, T...|Action|Adventure|...|\n",
      "|  26760|    60|   5.0|Wild Hearts Can't...|       Drama|Romance|\n",
      "|  33358|    60|   5.0|  Off the Map (2003)|        Comedy|Drama|\n",
      "|  40815|    60|   5.0|Harry Potter and ...|Adventure|Fantasy...|\n",
      "|   1967|    60|   5.0|    Labyrinth (1986)|Adventure|Fantasy...|\n",
      "|  54001|    60|   5.0|Harry Potter and ...|Adventure|Drama|F...|\n",
      "|  55247|    60|   5.0|Into the Wild (2007)|Action|Adventure|...|\n",
      "|  69844|    60|   5.0|Harry Potter and ...|Adventure|Fantasy...|\n",
      "|  71282|    60|   5.0|   Food, Inc. (2008)|         Documentary|\n",
      "|  81834|    60|   5.0|Harry Potter and ...|Action|Adventure|...|\n",
      "|  88125|    60|   5.0|Harry Potter and ...|Action|Adventure|...|\n",
      "|  91500|    60|   5.0|Hunger Games, The...|Action|Adventure|...|\n",
      "|  40870|    60|   5.0|   C.R.A.Z.Y. (2005)|               Drama|\n",
      "|   6016|    60|   5.0|City of God (Cida...|Action|Adventure|...|\n",
      "|  45722|    60|   5.0|Pirates of the Ca...|Action|Adventure|...|\n",
      "|   8368|    60|   5.0|Harry Potter and ...|Adventure|Fantasy...|\n",
      "|    157|    60|   4.5|Canadian Bacon (1...|          Comedy|War|\n",
      "|    364|    60|   4.5|Lion King, The (1...|Adventure|Animati...|\n",
      "|   2009|    60|   4.5|Soylent Green (1973)|Drama|Mystery|Sci...|\n",
      "+-------+------+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "User 60s Recommendations:\n",
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|    60|[[121029, 5.86924...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Look at user 60's ratings\n",
    "print(\"User 60's Ratings:\")\n",
    "original_ratings.filter(col(\"userId\") == 60).sort(\"rating\", ascending = False).show()\n",
    "\n",
    "# Look at the movies recommended to user 60\n",
    "print(\"User 60s Recommendations:\")\n",
    "als_recommendations.filter(col(\"userId\") == 60).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using gridsearch and cross validation\n",
    "\n",
    "this is another way to build the model with hyperparameter tunning \n",
    "\n",
    "\n",
    "note : computationaly expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.recommendation.ALS"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the required functions\n",
    "\n",
    "# Create test and train set\n",
    "(train, test) = ratings.randomSplit([0.8, 0.2], seed = 1234)\n",
    "\n",
    "# Create ALS model\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", nonnegative = True, implicitPrefs = False)\n",
    "\n",
    "# Confirm that a model called \"als\" was created\n",
    "type(als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models to be tested:  64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add hyperparameters and their respective values to param_grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "           .addGrid(als.rank, [10, 50, 75, 100]) \\\n",
    "           .addGrid(als.maxIter, [5, 50, 100, 200]) \\\n",
    "           .addGrid(als.regParam, [.01, .05, .1, .15]) \\\n",
    "           .build()\n",
    "\n",
    "# Define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "print (\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build your cross validation pipeline\n",
    "Now that we have our data, our train/test splits, our model, and our hyperparameter values, let's tell Spark how to cross validate our model so it can find the best combination of hyperparameters and return it to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValidator_f0b7f744c192\n"
     ]
    }
   ],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Confirm cv was built\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Model and Best Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit cross validator to the 'train' dataset\n",
    "model = cv.fit(train)\n",
    "\n",
    "#Extract best model from the cv model above\n",
    "best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best_model\n",
    "print(type(best_model))\n",
    "\n",
    "# Complete the code below to extract the ALS model parameters\n",
    "print(\"**Best Model**\")\n",
    "\n",
    "# Print \"Rank\"\n",
    "print(\"  Rank:\", best_model.getRank())\n",
    "\n",
    "# Print \"MaxIter\"\n",
    "print(\"  MaxIter:\", best_model.getMaxIter())\n",
    "\n",
    "# Print \"RegParam\"\n",
    "print(\"  RegParam:\", best_model.getRegParam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This is the output when the model has been run over powerful machine\n",
    "\n",
    "\n",
    "\n",
    "**Best Model**\n",
    "      Rank: 50\n",
    "      MaxIter: 100\n",
    "      RegParam: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
